{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Knowledge Distillation with Hint Training: Experiment 3\n",
        "\n",
        "Multiple hint layers\n"
      ],
      "metadata": {
        "id": "IWgolZ-tdkau"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UvlphObFDDi1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "\n",
        "mean = torch.tensor([0.4914, 0.4822, 0.4465])\n",
        "std = torch.tensor([0.2009, 0.2009, 0.2009])\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = mean, std = std)])\n",
        "cifar_train_data = datasets.CIFAR100('./data', train=True, download=True, transform=transform)\n",
        "cifar_test_data = datasets.CIFAR100('./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(cifar_train_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(cifar_test_data, batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4y2M7k_yyyM",
        "outputId": "c41f3bbd-4238-4a55-eb51-8f15a032651b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169001437/169001437 [00:05<00:00, 29371384.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in train_loader:\n",
        "    print(x.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIc_TCekDs2w",
        "outputId": "dececd86-1802-4403-d303-e80164ce4059"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 3, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Network initializations"
      ],
      "metadata": {
        "id": "ZkoqqrFedp3W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "JPpZxkpuUXj9"
      },
      "outputs": [],
      "source": [
        "# Wide Shallow neural network class to be used as teacher:\n",
        "# 3 different instantiations where the hint layer parameters are returned, either first, second, or third convolutional layer\n",
        "\n",
        "class DeepNN(nn.Module):\n",
        "    def __init__(self, num_classes=100):\n",
        "        super(DeepNN, self).__init__()\n",
        "        self.features1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.features2 = nn.Sequential(\n",
        "            nn.Conv2d(128, 356, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.features3 = nn.Sequential(\n",
        "            nn.Conv2d(356, 356, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=4, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(3204, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features1(x)\n",
        "        conv_feature_map = x\n",
        "        x = self.features2(x)\n",
        "        conv_feature_map2 = x\n",
        "        x = self.features3(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x, conv_feature_map, conv_feature_map2\n",
        "\n",
        "class DeepNN2(nn.Module):\n",
        "    def __init__(self, num_classes=100):\n",
        "        super(DeepNN2, self).__init__()\n",
        "        self.features1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.features2 = nn.Sequential(\n",
        "            nn.Conv2d(128, 356, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.features3 = nn.Sequential(\n",
        "            nn.Conv2d(356, 356, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=4, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(3204, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features1(x)\n",
        "        x = self.features2(x)\n",
        "        conv_feature_map = x\n",
        "        x = self.features3(x)\n",
        "        conv_feature_map2 = x\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x, conv_feature_map, conv_feature_map2\n",
        "\n",
        "class DeepNN3(nn.Module):\n",
        "    def __init__(self, num_classes=100):\n",
        "        super(DeepNN3, self).__init__()\n",
        "        self.features1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.features2 = nn.Sequential(\n",
        "            nn.Conv2d(128, 356, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.features3 = nn.Sequential(\n",
        "            nn.Conv2d(356, 356, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=4, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(3204, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features1(x)\n",
        "        conv_feature_map = x\n",
        "        x = self.features2(x)\n",
        "        x = self.features3(x)\n",
        "        conv_feature_map2 = x\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x, conv_feature_map, conv_feature_map2\n",
        "\n",
        "\n",
        "\n",
        "# Lightweight neural network class to be used as student, much deeper but thinner network:\n",
        "class LightNN(nn.Module):\n",
        "    def __init__(self, num_classes=100):\n",
        "        super(LightNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(32, 48, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(48, 48, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(48, 48, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=4, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(432, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        conv_feature_map = x\n",
        "        conv_feature_map1 = x\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x, conv_feature_map, conv_feature_map1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training and testing loop normal\n",
        "def test(model, test_dl):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    num = 0\n",
        "    with torch.no_grad():\n",
        "        for (X, y) in test_dl:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            y_pred , _, _ = model(X)\n",
        "            y_pred = torch.argmax(y_pred, dim=1)\n",
        "            correct += torch.eq(y, y_pred).sum()\n",
        "            num += X.shape[0]\n",
        "\n",
        "    accuracy = correct / num\n",
        "    return accuracy.item()\n",
        "\n",
        "def train(model, lr, num_epochs, train_dl, test_dl):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    test_accuracy_list = []\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        model.train()\n",
        "        for X, y in train_dl:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            opt.zero_grad()\n",
        "            y_pred, _, _ = model(X)\n",
        "            loss = loss_fn(y_pred, y)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "        test_accuracy = test(model, test_dl)\n",
        "        print(f\"Test accuracy at epoch {epoch}: {test_accuracy:.4f}\")\n",
        "        test_accuracy_list.append(test_accuracy)\n",
        "    return test_accuracy_list"
      ],
      "metadata": {
        "id": "unhyppwizpwd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training teacher for 10 epochs\n",
        "lr =  0.001\n",
        "num_epochs = 15\n",
        "teacher = DeepNN()\n",
        "\n",
        "x = train(teacher, lr, num_epochs, train_loader, test_loader)\n",
        "test_accuracy = test(teacher, test_loader)\n",
        "print(f\"Final teacher test accuracy on CIFAR-100: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtBLNNkizyxS",
        "outputId": "73fdf092-d17e-4597-85de-c9ce79876ef0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy at epoch 1: 0.2317\n",
            "Test accuracy at epoch 2: 0.3249\n",
            "Test accuracy at epoch 3: 0.3723\n",
            "Test accuracy at epoch 4: 0.4174\n",
            "Test accuracy at epoch 5: 0.4372\n",
            "Test accuracy at epoch 6: 0.4449\n",
            "Test accuracy at epoch 7: 0.4490\n",
            "Test accuracy at epoch 8: 0.4523\n",
            "Test accuracy at epoch 9: 0.4561\n",
            "Test accuracy at epoch 10: 0.4596\n",
            "Test accuracy at epoch 11: 0.4596\n",
            "Test accuracy at epoch 12: 0.4526\n",
            "Test accuracy at epoch 13: 0.4586\n",
            "Test accuracy at epoch 14: 0.4502\n",
            "Test accuracy at epoch 15: 0.4520\n",
            "Final teacher test accuracy on CIFAR-100: 0.4520\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#student model training\n",
        "lr =  0.001\n",
        "num_epochs = 15\n",
        "student = LightNN()\n",
        "\n",
        "x = train(student, lr, num_epochs, train_loader, test_loader)\n",
        "test_accuracy = test(student, test_loader)\n",
        "print(f\"Final student test accuracy on CIFAR-100: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "X-3vcjJPGsgy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a348834-2548-4d53-f6c2-66aca0c43b6d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy at epoch 1: 0.0889\n",
            "Test accuracy at epoch 2: 0.1592\n",
            "Test accuracy at epoch 3: 0.2067\n",
            "Test accuracy at epoch 4: 0.2331\n",
            "Test accuracy at epoch 5: 0.2586\n",
            "Test accuracy at epoch 6: 0.2758\n",
            "Test accuracy at epoch 7: 0.3001\n",
            "Test accuracy at epoch 8: 0.3049\n",
            "Test accuracy at epoch 9: 0.3176\n",
            "Test accuracy at epoch 10: 0.3294\n",
            "Test accuracy at epoch 11: 0.3422\n",
            "Test accuracy at epoch 12: 0.3403\n",
            "Test accuracy at epoch 13: 0.3431\n",
            "Test accuracy at epoch 14: 0.3565\n",
            "Test accuracy at epoch 15: 0.3384\n",
            "Final student test accuracy on CIFAR-100: 0.3384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Distillation loss\n",
        "def test_d(model, test_dl):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    num = 0\n",
        "    with torch.no_grad():\n",
        "        for (X, y) in test_dl:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            y_pred, _, _ = model(X)\n",
        "            y_pred = torch.argmax(y_pred, dim=1)\n",
        "            correct += torch.eq(y, y_pred).sum()\n",
        "            num += X.shape[0]\n",
        "\n",
        "    accuracy = correct / num\n",
        "    return accuracy.item()\n",
        "\n",
        "def train_d(teacher, student, lr, num_epochs, temperature, alpha, train_dl, test_dl):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    teacher.to(device)\n",
        "    student.to(device)\n",
        "    opt = torch.optim.Adam(student.parameters(), lr=lr)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    test_accuracy_list = []\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        student.train()\n",
        "        running_loss = 0.0\n",
        "        for X, y in train_dl:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            opt.zero_grad()\n",
        "            student_logits, _, _ = student(X)\n",
        "            with torch.no_grad():\n",
        "                teacher_logits, _, _ = teacher(X)\n",
        "\n",
        "            student_probs = torch.softmax(student_logits / temperature, dim=1)\n",
        "\n",
        "\n",
        "            soft_targets = nn.functional.softmax(teacher_logits / temperature, dim=-1)\n",
        "            soft_prob = nn.functional.log_softmax(student_logits / temperature, dim=-1)\n",
        "            soft_targets_loss = -torch.sum(soft_targets * soft_prob) / soft_prob.size()[0] * (temperature**2)\n",
        "            label_loss = loss_fn(student_logits, y)\n",
        "            loss = 0.25 * soft_targets_loss + 0.75* label_loss\n",
        "\n",
        "\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        #print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "        test_accuracy = test(student, test_dl)\n",
        "        print(f\"Test accuracy at epoch {epoch}: {test_accuracy:.4f}\")\n",
        "        test_accuracy_list.append(test_accuracy)\n",
        "    return test_accuracy_list"
      ],
      "metadata": {
        "id": "H-cqqeJX0k_y"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr =  0.001\n",
        "num_epochs = 15\n",
        "student = LightNN()\n",
        "\n",
        "train_d(teacher, student, lr, num_epochs, 2, .75, train_loader, test_loader)\n",
        "test_accuracy = test_d(student, test_loader)\n",
        "print(f\"Final student test accuracy on CIFAR-10: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Swo_bSh3nM9",
        "outputId": "b891558e-c004-455d-a55b-0245f7e99975"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy at epoch 1: 0.0702\n",
            "Test accuracy at epoch 2: 0.1453\n",
            "Test accuracy at epoch 3: 0.1937\n",
            "Test accuracy at epoch 4: 0.2305\n",
            "Test accuracy at epoch 5: 0.2454\n",
            "Test accuracy at epoch 6: 0.2739\n",
            "Test accuracy at epoch 7: 0.2870\n",
            "Test accuracy at epoch 8: 0.3071\n",
            "Test accuracy at epoch 9: 0.3226\n",
            "Test accuracy at epoch 10: 0.3200\n",
            "Test accuracy at epoch 11: 0.3457\n",
            "Test accuracy at epoch 12: 0.3508\n",
            "Test accuracy at epoch 13: 0.3566\n",
            "Test accuracy at epoch 14: 0.3607\n",
            "Test accuracy at epoch 15: 0.3683\n",
            "Final student test accuracy on CIFAR-10: 0.3683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "i3nziVFLUXkD"
      },
      "outputs": [],
      "source": [
        "class ModifiedLightNNRegressor(nn.Module):\n",
        "    def __init__(self, num_classes=100):\n",
        "        super(ModifiedLightNNRegressor, self).__init__()\n",
        "        self.features1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        self.features2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.features3= nn.Sequential(\n",
        "            nn.Conv2d(32, 48, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(48, 48, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(48, 48, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=4, stride=2),\n",
        "        )\n",
        "\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Conv2d(16, 128, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "        self.regressor1 = nn.Sequential(\n",
        "            nn.Conv2d(32, 356, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(432, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features1(x)\n",
        "        regressor_output = self.regressor(x)\n",
        "        x = self.features2(x)\n",
        "        regressor_output1 = self.regressor1(x)\n",
        "        x = self.features3(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x, regressor_output, regressor_output1\n",
        "\n",
        "\n",
        "\n",
        "class ModifiedLightNNRegressor2(nn.Module):\n",
        "    def __init__(self, num_classes=100):\n",
        "        super(ModifiedLightNNRegressor2, self).__init__()\n",
        "        self.features1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        self.features2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.features3= nn.Sequential(\n",
        "            nn.Conv2d(32, 48, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(48, 48, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(48, 48, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=4, stride=2),\n",
        "        )\n",
        "\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Conv2d(32, 356, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "        self.regressor1 = nn.Sequential(\n",
        "            nn.Conv2d(48, 356, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(432, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features1(x)\n",
        "        x = self.features2(x)\n",
        "        regressor_output = self.regressor(x)\n",
        "        x = self.features3(x)\n",
        "        regressor_output1 = self.regressor1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x, regressor_output, regressor_output1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class ModifiedLightNNRegressor3(nn.Module):\n",
        "    def __init__(self, num_classes=100):\n",
        "        super(ModifiedLightNNRegressor3, self).__init__()\n",
        "        self.features1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        self.features2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.features3= nn.Sequential(\n",
        "            nn.Conv2d(32, 48, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(48, 48, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(48, 48, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=4, stride=2),\n",
        "        )\n",
        "\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Conv2d(16, 128, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "        self.regressor1 = nn.Sequential(\n",
        "            nn.Conv2d(48, 356, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(432, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features1(x)\n",
        "        regressor_output = self.regressor(x)\n",
        "        x = self.features2(x)\n",
        "        x = self.features3(x)\n",
        "        regressor_output1 = self.regressor1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x, regressor_output, regressor_output1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Distillation loss\n",
        "def test_d(model, test_dl):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    num = 0\n",
        "    with torch.no_grad():\n",
        "        for (X, y) in test_dl:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            y_pred, _, _ = model(X)\n",
        "            y_pred = torch.argmax(y_pred, dim=1)\n",
        "            correct += torch.eq(y, y_pred).sum()\n",
        "            num += X.shape[0]\n",
        "\n",
        "    accuracy = correct / num\n",
        "    return accuracy.item()\n",
        "\n",
        "def train_d1(teacher, student, lr, num_epochs, temperature, alpha, train_dl, test_dl):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    teacher.to(device)\n",
        "    student.to(device)\n",
        "    opt = torch.optim.Adam(student.parameters(), lr=lr)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    mse_loss = nn.MSELoss()\n",
        "\n",
        "    test_accuracy_list = []\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        student.train()\n",
        "        running_loss = 0.0\n",
        "        for X, y in train_dl:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            opt.zero_grad()\n",
        "            student_logits, regressor_feature_map, regressor_feature_map1 = student(X)\n",
        "            with torch.no_grad():\n",
        "                teacher_logits, teacher_feature_map, teacher_feature_map1 = teacher(X)\n",
        "\n",
        "            hidden_rep_loss = mse_loss(regressor_feature_map, regressor_feature_map)\n",
        "            hidden_rep_loss1 = mse_loss(regressor_feature_map1, regressor_feature_map1)\n",
        "            label_loss = loss_fn(student_logits, y)\n",
        "            loss = .75*label_loss + .125*hidden_rep_loss + .125*hidden_rep_loss1\n",
        "\n",
        "\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        #print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "        test_accuracy = test(student, test_dl)\n",
        "        print(f\"Test accuracy at epoch {epoch}: {test_accuracy:.4f}\")\n",
        "        test_accuracy_list.append(test_accuracy)\n",
        "    return test_accuracy_list\n",
        "\n",
        "\n",
        "# Initialize a ModifiedLightNNRegressor\n",
        "torch.manual_seed(42)\n",
        "modified_nn_light_reg = ModifiedLightNNRegressor(num_classes=100).to(device)\n",
        "modified_nn_light_reg2 = ModifiedLightNNRegressor2(num_classes=100).to(device)\n",
        "modified_nn_light_reg3 = ModifiedLightNNRegressor3(num_classes=100).to(device)\n",
        "\n",
        "# We do not have to train the modified deep network from scratch of course, we just load its weights from the trained instance\n",
        "modified_nn_deep_reg = DeepNN(num_classes=100).to(device)\n",
        "modified_nn_deep_reg.load_state_dict(teacher.state_dict())\n",
        "modified_nn_deep_reg2 = DeepNN2(num_classes=100).to(device)\n",
        "modified_nn_deep_reg2.load_state_dict(teacher.state_dict())\n",
        "modified_nn_deep_reg3 = DeepNN3(num_classes=100).to(device)\n",
        "modified_nn_deep_reg3.load_state_dict(teacher.state_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiFhoqkyoTcW",
        "outputId": "af2f493c-5c56-4dd6-f894-acc770f17fcf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in modified_nn_light_reg.classifier.parameters():\n",
        "  param.requires_grad = False\n",
        "for param in modified_nn_light_reg2.classifier.parameters():\n",
        "  param.requires_grad = False\n",
        "for param in modified_nn_light_reg3.classifier.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "# Train and test once again\n",
        "train_d1(teacher=modified_nn_deep_reg, student=modified_nn_light_reg, lr=0.001, num_epochs=10, temperature=0, alpha = 0, train_dl=train_loader, test_dl=test_loader)\n",
        "train_d1(teacher=modified_nn_deep_reg2, student=modified_nn_light_reg2, lr=0.001, num_epochs=10, temperature=0, alpha = 0, train_dl=train_loader, test_dl=test_loader)\n",
        "train_d1(teacher=modified_nn_deep_reg3, student=modified_nn_light_reg3, lr=0.001, num_epochs=10, temperature=0, alpha = 0, train_dl=train_loader, test_dl=test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXxePnJdH8SV",
        "outputId": "d84de90c-c053-4486-8622-8a26eba8e545"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy at epoch 1: 0.0289\n",
            "Test accuracy at epoch 2: 0.0562\n",
            "Test accuracy at epoch 3: 0.0810\n",
            "Test accuracy at epoch 4: 0.1040\n",
            "Test accuracy at epoch 5: 0.1138\n",
            "Test accuracy at epoch 6: 0.1260\n",
            "Test accuracy at epoch 7: 0.1417\n",
            "Test accuracy at epoch 8: 0.1480\n",
            "Test accuracy at epoch 9: 0.1617\n",
            "Test accuracy at epoch 10: 0.1611\n",
            "Test accuracy at epoch 1: 0.0341\n",
            "Test accuracy at epoch 2: 0.0469\n",
            "Test accuracy at epoch 3: 0.0646\n",
            "Test accuracy at epoch 4: 0.0762\n",
            "Test accuracy at epoch 5: 0.0912\n",
            "Test accuracy at epoch 6: 0.1058\n",
            "Test accuracy at epoch 7: 0.1228\n",
            "Test accuracy at epoch 8: 0.1409\n",
            "Test accuracy at epoch 9: 0.1389\n",
            "Test accuracy at epoch 10: 0.1565\n",
            "Test accuracy at epoch 1: 0.0247\n",
            "Test accuracy at epoch 2: 0.0549\n",
            "Test accuracy at epoch 3: 0.0715\n",
            "Test accuracy at epoch 4: 0.0906\n",
            "Test accuracy at epoch 5: 0.1023\n",
            "Test accuracy at epoch 6: 0.1307\n",
            "Test accuracy at epoch 7: 0.1279\n",
            "Test accuracy at epoch 8: 0.1498\n",
            "Test accuracy at epoch 9: 0.1551\n",
            "Test accuracy at epoch 10: 0.1657\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.024699999019503593,\n",
              " 0.054899998009204865,\n",
              " 0.07149999588727951,\n",
              " 0.09059999883174896,\n",
              " 0.1022999957203865,\n",
              " 0.1306999921798706,\n",
              " 0.12789998948574066,\n",
              " 0.14980000257492065,\n",
              " 0.1551000028848648,\n",
              " 0.16569998860359192]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#unfreeze parameters and train finally with knowledge distillation for stage 2\n",
        "\n",
        "for param in modified_nn_light_reg.classifier.parameters():\n",
        "  param.requires_grad = True\n",
        "for param in modified_nn_light_reg2.classifier.parameters():\n",
        "  param.requires_grad = True\n",
        "for param in modified_nn_light_reg3.classifier.parameters():\n",
        "  param.requires_grad = True\n",
        "\n",
        "\n",
        "def test_d(model, test_dl):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    num = 0\n",
        "    with torch.no_grad():\n",
        "        for (X, y) in test_dl:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            y_pred, _, _ = model(X)\n",
        "            y_pred = torch.argmax(y_pred, dim=1)\n",
        "            correct += torch.eq(y, y_pred).sum()\n",
        "            num += X.shape[0]\n",
        "\n",
        "    accuracy = correct / num\n",
        "    return accuracy.item()\n",
        "\n",
        "def train_d(teacher, student, lr, num_epochs, temperature, alpha, train_dl, test_dl):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    teacher.to(device)\n",
        "    student.to(device)\n",
        "    opt = torch.optim.Adam(student.parameters(), lr=lr)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    test_accuracy_list = []\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        student.train()\n",
        "        running_loss = 0.0\n",
        "        for X, y in train_dl:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            opt.zero_grad()\n",
        "            student_logits, _, _ = student(X)\n",
        "            with torch.no_grad():\n",
        "                teacher_logits, _, _ = teacher(X)\n",
        "\n",
        "            student_probs = torch.softmax(student_logits / temperature, dim=1)\n",
        "\n",
        "\n",
        "            soft_targets = nn.functional.softmax(teacher_logits / temperature, dim=-1)\n",
        "            soft_prob = nn.functional.log_softmax(student_logits / temperature, dim=-1)\n",
        "            soft_targets_loss = -torch.sum(soft_targets * soft_prob) / soft_prob.size()[0] * (temperature**2)\n",
        "            label_loss = loss_fn(student_logits, y)\n",
        "            loss = 0.25 * soft_targets_loss + 0.75* label_loss\n",
        "\n",
        "\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        #print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "        test_accuracy = test(student, test_dl)\n",
        "        print(f\"Test accuracy at epoch {epoch}: {test_accuracy:.4f}\")\n",
        "        test_accuracy_list.append(test_accuracy)\n",
        "    return test_accuracy_list"
      ],
      "metadata": {
        "id": "pC4lKIqPOfQe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_d(teacher=modified_nn_deep_reg, student=modified_nn_light_reg, lr=0.001, num_epochs=10, temperature=2, alpha = 0.75, train_dl=train_loader, test_dl=test_loader)\n",
        "train_d(teacher=modified_nn_deep_reg2, student=modified_nn_light_reg2,  lr=0.001, num_epochs=10, temperature=2, alpha = 0.75, train_dl=train_loader, test_dl=test_loader)\n",
        "train_d(teacher=modified_nn_deep_reg3, student=modified_nn_light_reg3,  lr=0.001, num_epochs=10, temperature=2, alpha = 0.75, train_dl=train_loader, test_dl=test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnxFh-JIP__p",
        "outputId": "dc740a66-ba75-4257-e042-1c306ba33d89"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy at epoch 1: 0.2329\n",
            "Test accuracy at epoch 2: 0.2528\n",
            "Test accuracy at epoch 3: 0.2784\n",
            "Test accuracy at epoch 4: 0.2986\n",
            "Test accuracy at epoch 5: 0.3014\n",
            "Test accuracy at epoch 6: 0.3100\n",
            "Test accuracy at epoch 7: 0.3273\n",
            "Test accuracy at epoch 8: 0.3254\n",
            "Test accuracy at epoch 9: 0.3341\n",
            "Test accuracy at epoch 10: 0.3348\n",
            "Test accuracy at epoch 1: 0.2242\n",
            "Test accuracy at epoch 2: 0.2625\n",
            "Test accuracy at epoch 3: 0.2830\n",
            "Test accuracy at epoch 4: 0.3049\n",
            "Test accuracy at epoch 5: 0.3115\n",
            "Test accuracy at epoch 6: 0.3349\n",
            "Test accuracy at epoch 7: 0.3414\n",
            "Test accuracy at epoch 8: 0.3470\n",
            "Test accuracy at epoch 9: 0.3500\n",
            "Test accuracy at epoch 10: 0.3609\n",
            "Test accuracy at epoch 1: 0.2416\n",
            "Test accuracy at epoch 2: 0.2684\n",
            "Test accuracy at epoch 3: 0.2932\n",
            "Test accuracy at epoch 4: 0.2908\n",
            "Test accuracy at epoch 5: 0.3092\n",
            "Test accuracy at epoch 6: 0.3317\n",
            "Test accuracy at epoch 7: 0.3396\n",
            "Test accuracy at epoch 8: 0.3437\n",
            "Test accuracy at epoch 9: 0.3442\n",
            "Test accuracy at epoch 10: 0.3552\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.24159999191761017,\n",
              " 0.2683999836444855,\n",
              " 0.29319998621940613,\n",
              " 0.290800005197525,\n",
              " 0.3091999888420105,\n",
              " 0.33169999718666077,\n",
              " 0.33959999680519104,\n",
              " 0.34369999170303345,\n",
              " 0.3441999852657318,\n",
              " 0.35519999265670776]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CazQHdKiYwwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "LC9GhxKx4PL_"
      },
      "outputs": [],
      "source": [
        "def test_multiple_outputs(model, test_loader, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs, _, _ = model(inputs) # Disregard the second tensor of the tuple\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Teacher Accuracy:\")\n",
        "test_accuracy_deep = test(modified_nn_deep_reg, test_loader)\n",
        "print(f\"{(100*test_accuracy_deep):.2f}%\")\n",
        "\n",
        "test_accuracy = test_d(student, test_loader)\n",
        "print(f\"Student accuracy regular training: {(100*test_accuracy):.2f}%\")\n",
        "\n",
        "print(f\"Final Student Accuracy (Hint = 1,2):\")\n",
        "test_accuracy_light_ce_and_mse_loss1 = test_multiple_outputs(modified_nn_light_reg, test_loader, device)\n",
        "print(f\"Final Student Accuracy (Hint = 2,3):\")\n",
        "test_accuracy_light_ce_and_mse_loss2 = test_multiple_outputs(modified_nn_light_reg2, test_loader, device)\n",
        "print(f\"Final Student Accuracy (Hint = 1,3):\")\n",
        "test_accuracy_light_ce_and_mse_loss3 = test_multiple_outputs(modified_nn_light_reg3, test_loader, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t97x9NPtYgLe",
        "outputId": "8a2fe7a8-8ac2-40dd-dcc6-713b56f5f55f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher Accuracy:\n",
            "45.20%\n",
            "Student accuracy regular training: 33.84%\n",
            "Final Student Accuracy (Hint = 1,2):\n",
            "Test Accuracy: 33.48%\n",
            "Final Student Accuracy (Hint = 2,3):\n",
            "Test Accuracy: 36.09%\n",
            "Final Student Accuracy (Hint = 1,3):\n",
            "Test Accuracy: 35.52%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn_light = LightNN(num_classes=100).to(device)\n",
        "total_params_deep = \"{:,}\".format(sum(p.numel() for p in teacher.parameters()))\n",
        "print(f\"DeepNN parameters: {total_params_deep}\")\n",
        "total_params_light = \"{:,}\".format(sum(p.numel() for p in student.parameters()))\n",
        "print(f\"LightNN parameters: {total_params_light}\")\n",
        "total_params_light = \"{:,}\".format(sum(p.numel() for p in modified_nn_light_reg.parameters()))\n",
        "print(f\"LightNN parameters: {total_params_light}\")\n",
        "total_params_light = \"{:,}\".format(sum(p.numel() for p in modified_nn_light_reg2.parameters()))\n",
        "print(f\"LightNN parameters: {total_params_light}\")\n",
        "total_params_light = \"{:,}\".format(sum(p.numel() for p in modified_nn_light_reg3.parameters()))\n",
        "print(f\"LightNN parameters: {total_params_light}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HVR6AyHYsjd",
        "outputId": "1485566e-81b9-4fb1-d7dd-0750bf605def"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DeepNN parameters: 3,247,292\n",
            "LightNN parameters: 151,988\n",
            "LightNN parameters: 273,432\n",
            "LightNN parameters: 409,020\n",
            "LightNN parameters: 324,696\n"
          ]
        }
      ]
    }
  ]
}